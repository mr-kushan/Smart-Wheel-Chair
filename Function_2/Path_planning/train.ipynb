{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Batt</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Wpts</th>\n",
       "      <th>Emot</th>\n",
       "      <th>Comf</th>\n",
       "      <th>Traf</th>\n",
       "      <th>Score</th>\n",
       "      <th>Relev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.037661</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.249895</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.338252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.111925</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.357789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-1.086373</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.175459</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-1.309166</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.676109</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Query  Batt    Dist    Wpts   Emot    Comf  Traf     Score  Relev\n",
       "0          1  0.36  0.6667  0.5500  0.500  0.0000  0.40  0.828808    2.0\n",
       "1          1  0.41  0.5000  0.5500  0.750  0.0000  0.40  1.037661    1.0\n",
       "2          1  0.44  1.0000  0.5000  0.875  0.5000  0.40  0.249895    3.0\n",
       "3          1  0.65  1.0000  0.5167  0.750  0.4167  0.40 -0.338252    5.0\n",
       "4          1  0.71  0.7143  0.6000  0.800  0.1000  0.40  0.111925    4.0\n",
       "...      ...   ...     ...     ...    ...     ...   ...       ...    ...\n",
       "49995  10000  0.46  0.5000  0.7500  1.000  0.2500  0.42  1.357789    1.0\n",
       "49996  10000  0.47  1.0000  0.1500  0.750  0.0000  0.42 -1.086373    3.0\n",
       "49997  10000  0.20  0.5000  0.1000  1.000  1.0000  0.42 -2.175459    5.0\n",
       "49998  10000  0.65  0.5000  0.3667  0.500  0.1667  0.42 -1.309166    4.0\n",
       "49999  10000  0.41  0.5000  0.5500  0.500  0.2500  0.42  0.676109    2.0\n",
       "\n",
       "[50000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "data  = pd.read_csv('query_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your dataset is in a pandas DataFrame named `data`\n",
    "features = ['Batt', 'Dist', 'Wpts', 'Emot', 'Comf', 'Traf']\n",
    "x = data[features]\n",
    "y = data['Relev']\n",
    "group_ids = data.groupby('Query').size().values  # Get the number of paths per query\n",
    "# Assuming your data is in a pandas DataFrame named `data`\n",
    "# Group the dataset by Query to get unique queries\n",
    "queries = data['Query'].unique()\n",
    "\n",
    "# Validate that group sizes sum to the total number of samples\n",
    "assert group_ids.sum() == data.shape[0], (\n",
    "    f\"Mismatch in group sizes: sum(group_ids) = {group_ids.sum()}, \"\n",
    "    f\"but total samples = {data.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the queries into training and validation sets\n",
    "train_queries, val_queries = train_test_split(queries, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create masks for training and validation sets\n",
    "train_mask = data['Query'].isin(train_queries)\n",
    "val_mask = data['Query'].isin(val_queries)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train = data[train_mask][features]\n",
    "y_train = data[train_mask]['Relev']\n",
    "x_val = data[val_mask][features]\n",
    "y_val = data[val_mask]['Relev']\n",
    "\n",
    "# Get the group sizes for training and validation\n",
    "train_group_sizes = data[train_mask].groupby('Query').size().values\n",
    "val_group_sizes = data[val_mask].groupby('Query').size().values\n",
    "\n",
    "# Validate training set group sizes\n",
    "assert train_group_sizes.sum() == x_train.shape[0], (\n",
    "    f\"Mismatch in train group sizes: sum(train_group_sizes) = {train_group_sizes.sum()}, \"\n",
    "    f\"but total training samples = {x_train.shape[0]}\"\n",
    ")\n",
    "\n",
    "# Validate validation set group sizes\n",
    "assert val_group_sizes.sum() == x_val.shape[0], (\n",
    "    f\"Mismatch in val group sizes: sum(val_group_sizes) = {val_group_sizes.sum()}, \"\n",
    "    f\"but total validation samples = {x_val.shape[0]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 434\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create LightGBM datasets for training and validation\n",
    "train_data = lgb.Dataset(x_train, label=y_train, group=train_group_sizes)\n",
    "val_data = lgb.Dataset(x_val, label=y_val, group=val_group_sizes)\n",
    "\n",
    "params = {\n",
    "    'objective': 'lambdarank',  # Objective for ranking\n",
    "    'metric': 'ndcg',  # NDCG for ranking tasks\n",
    "    'ndcg_eval_at': [1, 3, 5],  # Evaluate NDCG at different levels\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    valid_sets=[train_data, val_data],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)  # Predicted relevance scores\n",
    "len(y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
