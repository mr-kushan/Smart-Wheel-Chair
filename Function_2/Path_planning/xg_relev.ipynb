{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Batt</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Wpts</th>\n",
       "      <th>Emot</th>\n",
       "      <th>Comf</th>\n",
       "      <th>Traf</th>\n",
       "      <th>Score</th>\n",
       "      <th>Relev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.571159</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.107488</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.276850</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.043321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.050039</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.569033</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.069465</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.464240</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.788080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-2.457573</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Query  Batt    Dist    Wpts   Emot  Comf  Traf     Score  Relev\n",
       "0            1  0.45  0.5000  0.3000  0.500  0.00  0.65 -0.571159    3.0\n",
       "1            1  0.61  0.5000  0.1667  1.000  0.50  0.65 -1.107488    5.0\n",
       "2            1  0.91  0.5556  0.5200  0.600  0.20  0.65 -0.276850    2.0\n",
       "3            1  0.83  0.5000  0.4000  0.875  0.25  0.65  0.043321    1.0\n",
       "4            1  0.46  0.5000  0.0500  1.000  0.50  0.65 -1.050039    4.0\n",
       "...        ...   ...     ...     ...    ...   ...   ...       ...    ...\n",
       "499995  100000  0.41  0.5000  1.0000  0.750  0.50  0.93  1.569033    2.0\n",
       "499996  100000  0.52  0.4000  0.2500  1.000  0.25  0.93 -0.069465    3.0\n",
       "499997  100000  0.39  0.6667  0.0500  1.000  0.25  0.93 -0.464240    4.0\n",
       "499998  100000  0.34  0.6667  0.7500  1.000  0.25  0.93  1.788080    1.0\n",
       "499999  100000  0.19  1.0000  0.1000  0.000  0.00  0.93 -2.457573    5.0\n",
       "\n",
       "[500000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"query_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features and target\n",
    "X = data[[\"Batt\", \"Dist\", \"Wpts\", \"Emot\", \"Comf\", \"Traf\"]]\n",
    "y = data[\"Relev\"]\n",
    "group = data.groupby(\"Query\").size().to_list()  # Number of rows per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get unique queries\n",
    "unique_queries = data['Query'].unique()\n",
    "\n",
    "# Split queries into train and test sets\n",
    "train_queries, test_queries = train_test_split(unique_queries, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training and testing data based on the query splits\n",
    "train_mask = data['Query'].isin(train_queries)\n",
    "test_mask = data['Query'].isin(test_queries)\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "# Compute groups for train and test sets\n",
    "group_train = data[train_mask].groupby('Query').size().to_list()\n",
    "group_test = data[test_mask].groupby('Query').size().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batt</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Wpts</th>\n",
       "      <th>Emot</th>\n",
       "      <th>Comf</th>\n",
       "      <th>Traf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Batt  Dist   Wpts    Emot    Comf  Traf\n",
       "40  0.87  0.50  0.625  1.0000  0.1250  0.58\n",
       "41  0.43  0.75  0.200  0.8333  0.1667  0.58\n",
       "42  0.41  0.50  0.500  0.7500  0.2500  0.58\n",
       "43  0.25  0.50  0.500  1.0000  0.0000  0.58\n",
       "44  0.25  0.50  0.500  0.5000  0.5000  0.58"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the training data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.set_group(group_train)  # Set group sizes for training\n",
    "\n",
    "# Prepare the test data\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dtest.set_group(group_test)  # Set group sizes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"rank:pairwise\",  # Use pairwise ranking objective\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"eval_metric\": \"ndcg\",  # Evaluation metric\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-ndcg:0.96361\n",
      "[1]\tTest-ndcg:0.97205\n",
      "[2]\tTest-ndcg:0.97867\n",
      "[3]\tTest-ndcg:0.98210\n",
      "[4]\tTest-ndcg:0.98357\n",
      "[5]\tTest-ndcg:0.98398\n",
      "[6]\tTest-ndcg:0.98528\n",
      "[7]\tTest-ndcg:0.98634\n",
      "[8]\tTest-ndcg:0.98638\n",
      "[9]\tTest-ndcg:0.98720\n",
      "[10]\tTest-ndcg:0.98724\n",
      "[11]\tTest-ndcg:0.98748\n",
      "[12]\tTest-ndcg:0.98795\n",
      "[13]\tTest-ndcg:0.98828\n",
      "[14]\tTest-ndcg:0.98875\n",
      "[15]\tTest-ndcg:0.98875\n",
      "[16]\tTest-ndcg:0.98899\n",
      "[17]\tTest-ndcg:0.98937\n",
      "[18]\tTest-ndcg:0.98937\n",
      "[19]\tTest-ndcg:0.98973\n",
      "[20]\tTest-ndcg:0.99000\n",
      "[21]\tTest-ndcg:0.98995\n",
      "[22]\tTest-ndcg:0.99051\n",
      "[23]\tTest-ndcg:0.99054\n",
      "[24]\tTest-ndcg:0.99058\n",
      "[25]\tTest-ndcg:0.99062\n",
      "[26]\tTest-ndcg:0.99100\n",
      "[27]\tTest-ndcg:0.99131\n",
      "[28]\tTest-ndcg:0.99147\n",
      "[29]\tTest-ndcg:0.99156\n",
      "[30]\tTest-ndcg:0.99170\n",
      "[31]\tTest-ndcg:0.99187\n",
      "[32]\tTest-ndcg:0.99196\n",
      "[33]\tTest-ndcg:0.99209\n",
      "[34]\tTest-ndcg:0.99221\n",
      "[35]\tTest-ndcg:0.99236\n",
      "[36]\tTest-ndcg:0.99234\n",
      "[37]\tTest-ndcg:0.99243\n",
      "[38]\tTest-ndcg:0.99250\n",
      "[39]\tTest-ndcg:0.99257\n",
      "[40]\tTest-ndcg:0.99257\n",
      "[41]\tTest-ndcg:0.99247\n",
      "[42]\tTest-ndcg:0.99271\n",
      "[43]\tTest-ndcg:0.99280\n",
      "[44]\tTest-ndcg:0.99289\n",
      "[45]\tTest-ndcg:0.99294\n",
      "[46]\tTest-ndcg:0.99284\n",
      "[47]\tTest-ndcg:0.99305\n",
      "[48]\tTest-ndcg:0.99312\n",
      "[49]\tTest-ndcg:0.99315\n",
      "[50]\tTest-ndcg:0.99317\n",
      "[51]\tTest-ndcg:0.99315\n",
      "[52]\tTest-ndcg:0.99330\n",
      "[53]\tTest-ndcg:0.99344\n",
      "[54]\tTest-ndcg:0.99331\n",
      "[55]\tTest-ndcg:0.99332\n",
      "[56]\tTest-ndcg:0.99332\n",
      "[57]\tTest-ndcg:0.99337\n",
      "[58]\tTest-ndcg:0.99360\n",
      "[59]\tTest-ndcg:0.99368\n",
      "[60]\tTest-ndcg:0.99379\n",
      "[61]\tTest-ndcg:0.99384\n",
      "[62]\tTest-ndcg:0.99380\n",
      "[63]\tTest-ndcg:0.99400\n",
      "[64]\tTest-ndcg:0.99393\n",
      "[65]\tTest-ndcg:0.99400\n",
      "[66]\tTest-ndcg:0.99399\n",
      "[67]\tTest-ndcg:0.99409\n",
      "[68]\tTest-ndcg:0.99422\n",
      "[69]\tTest-ndcg:0.99423\n",
      "[70]\tTest-ndcg:0.99419\n",
      "[71]\tTest-ndcg:0.99430\n",
      "[72]\tTest-ndcg:0.99426\n",
      "[73]\tTest-ndcg:0.99434\n",
      "[74]\tTest-ndcg:0.99430\n",
      "[75]\tTest-ndcg:0.99433\n",
      "[76]\tTest-ndcg:0.99438\n",
      "[77]\tTest-ndcg:0.99444\n",
      "[78]\tTest-ndcg:0.99450\n",
      "[79]\tTest-ndcg:0.99450\n",
      "[80]\tTest-ndcg:0.99449\n",
      "[81]\tTest-ndcg:0.99444\n",
      "[82]\tTest-ndcg:0.99456\n",
      "[83]\tTest-ndcg:0.99462\n",
      "[84]\tTest-ndcg:0.99463\n",
      "[85]\tTest-ndcg:0.99478\n",
      "[86]\tTest-ndcg:0.99477\n",
      "[87]\tTest-ndcg:0.99478\n",
      "[88]\tTest-ndcg:0.99482\n",
      "[89]\tTest-ndcg:0.99481\n",
      "[90]\tTest-ndcg:0.99487\n",
      "[91]\tTest-ndcg:0.99482\n",
      "[92]\tTest-ndcg:0.99478\n",
      "[93]\tTest-ndcg:0.99479\n",
      "[94]\tTest-ndcg:0.99480\n",
      "[95]\tTest-ndcg:0.99485\n",
      "[96]\tTest-ndcg:0.99489\n",
      "[97]\tTest-ndcg:0.99493\n",
      "[98]\tTest-ndcg:0.99495\n",
      "[99]\tTest-ndcg:0.99494\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "rank_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict scores\n",
    "y_pred = rank_model.predict(dtest)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ranks: [2 1 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 5 items per query, rank them\n",
    "query_results = y_pred[:5]  # Adjust as per group\n",
    "ranked_positions = rankdata(-query_results, method=\"ordinal\")  # Rank in descending order\n",
    "\n",
    "print(\"Predicted Ranks:\", ranked_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model.save_model(\"xgboost_rank_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the test dataset (assuming it's a CSV file)\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Prepare the features and labels for evaluation\n",
    "X_test = test_data.drop(columns=['Query','Score','Relev'])\n",
    "y_test = test_data['Relev']  # The 'Relev' column is the true relevance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test data into DMatrix format\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score: 0.9941678989091123\n",
      "Mean Squared Error: 10.218516117531914\n"
     ]
    }
   ],
   "source": [
    "# Predict relevance scores for the test data\n",
    "y_pred = rank_model.predict(dtest)\n",
    "\n",
    "# Calculate NDCG (assuming relevance is given by 'y_test' and predicted relevance by 'y_pred')\n",
    "ndcg_score_result = ndcg_score([y_test], [y_pred])\n",
    "print(f'NDCG score: {ndcg_score_result}')\n",
    "\n",
    "# Optionally, you can compute Mean Squared Error (MSE) as a baseline evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.0\n",
      "1    4.0\n",
      "2    5.0\n",
      "3    3.0\n",
      "4    1.0\n",
      "Name: Relev, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "actual_rank = y_test[:5]\n",
    "print(actual_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 5 3 1]\n"
     ]
    }
   ],
   "source": [
    "actual_rank = rankdata(y_test[:5], method=\"ordinal\")\n",
    "print(actual_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Assuming y_pred and y_test are your predicted and true relevance values\n",
    "# # Get the number of query groups\n",
    "# num_groups = len(y_pred) // 5  # Total number of 5-item query groups\n",
    "\n",
    "# # Loop through the groups and print the predicted ranks vs true ranks\n",
    "# for i in range(num_groups):\n",
    "#     start = i * 5\n",
    "#     end = (i + 1) * 5\n",
    "    \n",
    "#     # Get predicted scores for the current query group\n",
    "#     query_results = y_pred[start:end]  # Adjust as per group\n",
    "#     ranked_positions = rankdata(query_results, method=\"ordinal\")  # Rank in descending order\n",
    "    \n",
    "#     # Get true relevance scores for the current query group\n",
    "#     actual_relevance = y_test[start:end]\n",
    "#     actual_rank = rankdata(actual_relevance, method=\"ordinal\")\n",
    "    \n",
    "#     print(f\"Group {i + 1}:\")\n",
    "#     print(\"Predicted Ranks:\", ranked_positions)\n",
    "#     print(\"True Ranks:\", actual_rank)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 5:\n",
      "Predicted Ranks: [5 4 3 1 2]\n",
      "True Ranks: [5 4 3 1 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_num = 5\n",
    "\n",
    "start = (group_num-1) * 5\n",
    "end   = group_num * 5\n",
    "\n",
    "# Get predicted scores for the current query group\n",
    "query_results = y_pred[start:end]  # Adjust as per group\n",
    "ranked_positions = rankdata(query_results, method=\"ordinal\")  # Rank in descending order\n",
    "\n",
    "# Get true relevance scores for the current query group\n",
    "actual_relevance = y_test[start:end]\n",
    "actual_rank = rankdata(actual_relevance, method=\"ordinal\")\n",
    "\n",
    "print(f\"Group {group_num}:\")\n",
    "print(\"Predicted Ranks:\", ranked_positions)\n",
    "print(\"True Ranks:\", actual_rank)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the number of query groups\n",
    "num_groups = len(y_pred) // 5  # Total number of 5-item query groups\n",
    "\n",
    "correct_count = 0  # Counter to track correct rankings\n",
    "total_count = 0  # Total number of groups\n",
    "\n",
    "# Loop through the groups and compare the predicted ranks vs true ranks\n",
    "for i in range(num_groups):\n",
    "    start = i * 5\n",
    "    end = (i + 1) * 5\n",
    "    \n",
    "    # Get predicted scores for the current query group\n",
    "    query_results = y_pred[start:end]  # Adjust as per group\n",
    "    ranked_positions = rankdata(query_results, method=\"ordinal\")  # Rank in descending order\n",
    "    \n",
    "    # Get true relevance scores for the current query group\n",
    "    actual_relevance = y_test[start:end]\n",
    "    actual_rank = rankdata(actual_relevance, method=\"ordinal\")\n",
    "    \n",
    "    # Compare predicted and actual ranks\n",
    "    if (ranked_positions == actual_rank).all():  # Check if ranks are exactly the same\n",
    "        correct_count += 1\n",
    "    \n",
    "    total_count += 1\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_count / total_count\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
